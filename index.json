[
{
	"uri": "/7-authentication-and-authorization/7.1-authenticate-with-cognito-api-gateway/",
	"title": "Configure Cognito Authentication in API Gateway",
	"tags": [],
	"description": "",
	"content": "Overview Amazon Cognito is a user management service that helps with authentication and issuing secure tokens (JWT) for clients to access the system. When integrated with API Gateway, you can configure user authentication using JWT tokens without writing extra code.\nMain Content Enable authentication for resources  Go to API Gateway Console → select the API eshop-fcj. In the left menu, choose Authorizers, then click Create an authorizer.  On the Authorizer details page, enter the following:    Authorizer name: cognito-authorizer-eshop-fcj\n  Authorizer type: Cognito\n  Cognito user pool: \u0026lt;your-user-pool\u0026gt;\n  Token source: Authorization\n  Then click Create authorizer\n  After creating the Authorizer, configure each method individually.  Configure for categories GET method\n Select resources categories with GET method, then click Edit.  In Edit method request, set the following:    Authorization: cognito-authorizer-eshop-fcj\n  Then click Save\n  Once completed, the method will appear like this:  Repeat the same Cognito authentication configuration for other methods\n1. POST /categories\n  Select method POST, then Edit method request\n  In Authorization, choose: cognito-authorizer-eshop-fcj\n  Save and confirm the result:\n  2. GET /categories/{id}\nSelect the GET method under {id}, then click Edit method request\n  In Authorization, choose: cognito-authorizer-eshop-fcj\n  Save, and the result will be:\n  3. PUT /categories/{id}\nSame as above:\n4. DELETE /categories/{id}\nSame as above:\nConfigure for products 1. POST /products\n  Select method POST, then Edit method request\n  In Authorization, choose: cognito-authorizer-eshop-fcj\n  Save and confirm:\n  2. GET /products\nSame as above:\n3. GET /products/{id}\nSame as above:\n4. PUT /products/{id}\nSame as above:\n5. DELETE /products/{id}\nSame as above:\nAfter completing the authentication configuration  In the API Gateway eshop-fcj, on the left sidebar, choose Deploy API.  In the Deploy API window, choose the stage to deploy and click Deploy to complete.  "
},
{
	"uri": "/6-setup-cognito-userpool/6.1-create-user-pool-and-setting/",
	"title": "Create and Configure User Pool",
	"tags": [],
	"description": "",
	"content": "Overview Amazon Cognito User Pool is an identity management service that allows you to create, authenticate, and manage users for your web or mobile application. In this section, we will create a basic User Pool to use in upcoming authentication steps.\nMain Steps  Go to the Amazon Cognito Console. Choose User pools from the left menu, then click Create user pool.  On the Set up resources for your application screen, under Define your application, enter the following:   Application type: Single-page application (SPA) Name your application: eshop-client-no-secret  In this workshop, the frontend calls Cognito directly for authentication, so you should choose Single-page application (SPA) to avoid generating a client secret, which simplifies integration from frontend or Postman.\n\rScroll down to Configure options, and configure as follows:   Sign-in options: Select Email so users can log in with email. Then click Create user directory to create the User Pool.  You may also enable email or phone number verification if needed.\nAdditionally, under Required attributes for sign-up, you can add user attributes like name, birthdate, or address to collect more data.\n\rOnce the User Pool is created, return to the Cognito dashboard, select your User Pool, and go to App clients under Applications — you will see the app client just created.  Click into the app client and select Edit.  In the Authentication flows section, enable:   ALLOW_USER_AUTH: Allows multiple types of authentication flows. ALLOW_USER_PASSWORD_AUTH: Allows login with username/password (required for API calls via Postman or frontend). ALLOW_REFRESH_TOKEN_AUTH: Allows refresh token for session extension.  Scroll down and click Save changes to apply configuration.  To enable user verification via email, go to the User Pool, select the Sign-up section from the left menu, then click Edit on the Attribute verification and user account confirmation section.  In the Edit attribute verification and user account confirmation screen, configure:   Allow Cognito to automatically send messages to verify and confirm – Recommended Send email message, verify email address Keep original attribute value active when an update is pending – Recommended Then click Save changes  From the left menu in the User Pool, go to Message templates → under Verification message, click Edit  In the Edit verification message section, set up:   Verification type: Code Email subject: Account verification code Email message:  \u0026lt;table width=\u0026#34;100%\u0026#34; cellpadding=\u0026#34;0\u0026#34; cellspacing=\u0026#34;0\u0026#34; style=\u0026#34;background-color: #f0f2f5; padding: 40px 0;\u0026#34;\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td align=\u0026#34;center\u0026#34;\u0026gt; \u0026lt;table width=\u0026#34;100%\u0026#34; style=\u0026#34;max-width:600px; background-color:#ffffff; border-radius:8px; overflow:hidden; font-family:Arial,sans-serif; box-shadow:0 4px 12px rgba(0,0,0,0.1);\u0026#34;\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td style=\u0026#34;background: linear-gradient(135deg, #06bbcc 0%, #2E86C1 100%); padding: 30px; text-align:center;\u0026#34;\u0026gt; \u0026lt;h1 style=\u0026#34;margin:0; color:#ffffff; font-size:24px; font-weight:normal;\u0026#34;\u0026gt; Welcome to \u0026lt;strong\u0026gt;eSHOP-FCJ\u0026lt;/strong\u0026gt; \u0026lt;/h1\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td style=\u0026#34;padding: 30px; color: #333333; font-size: 16px; line-height:1.6;\u0026#34;\u0026gt; \u0026lt;p\u0026gt;Hello \u0026lt;strong\u0026gt;User!\u0026lt;/strong\u0026gt;,\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; To complete your registration, please enter the verification code below: \u0026lt;/p\u0026gt; \u0026lt;p style=\u0026#34;text-align:center; margin: 30px 0;\u0026#34;\u0026gt; \u0026lt;span style=\u0026#34; display:inline-block; background-color:#06bbcc; color:#ffffff; font-size:28px; font-weight:bold; padding:15px 30px; border-radius:6px; border:2px solid #06bbcc; letter-spacing:4px; \u0026#34;\u0026gt; {{####}} \u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p style=\u0026#34;color:#7f8c8d; font-size:14px; text-align:center;\u0026#34;\u0026gt; This code will \u0026lt;strong\u0026gt;expire in 5 minutes\u0026lt;/strong\u0026gt;. \u0026lt;/p\u0026gt; \u0026lt;p style=\u0026#34;margin-top:30px;\u0026#34;\u0026gt; We are committed to protecting your information and privacy. \u0026lt;/p\u0026gt; \u0026lt;p style=\u0026#34;margin-top:30px;\u0026#34;\u0026gt; Best regards,\u0026lt;br\u0026gt; \u0026lt;em\u0026gt;The eSHOP-FCJ Team\u0026lt;/em\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td style=\u0026#34;background-color:#f0f2f5; padding:20px 30px; text-align:center; font-size:12px; color:#95a5a6;\u0026#34;\u0026gt; © 2024 eSHOP-FCJ. \u0026lt;a href=\u0026#34;https://your-domain.com\u0026#34; style=\u0026#34;color:#06bbcc; text-decoration:none;\u0026#34;\u0026gt;Visit our site\u0026lt;/a\u0026gt; | \u0026lt;a href=\u0026#34;mailto:support@your-domain.com\u0026#34; style=\u0026#34;color:#06bbcc; text-decoration:none;\u0026#34;\u0026gt;support@eshopfcj.com\u0026lt;/a\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; "
},
{
	"uri": "/5-config-api-gateway/5.1-create-api-gateway/",
	"title": "Create API Gateway",
	"tags": [],
	"description": "",
	"content": "Create API Gateway We will now configure API Gateway to interact with the Lambda functions created in the previous section:\n Open the Amazon API Gateway Console and click Create an API  In the Choose an API type section, scroll down and select REST API, then click Build   In the API details section, provide the following information:\n Select: New API API name: eshop-fcj Description (optional): eshop-fcj API endpoint type: Regional IP address type: IPv4    After clicking Create API, you will see the result as shown below:   "
},
{
	"uri": "/4-deploy-lambda-function/4.1-create-iam-role-for-lambda-function/",
	"title": "Create IAM Role for Lambda Function",
	"tags": [],
	"description": "",
	"content": "Overview Before deploying any Lambda function, you must create an IAM Role – which grants permission for the Lambda function to access other AWS services, such as reading/writing data in DynamoDB.\nIn this section, we’ll grant appropriate permissions.\nIAM (Identity and Access Management) acts as a permission layer, allowing Lambda to securely operate in your AWS environment.\n Steps to Create IAM Role for Lambda Functions Working with DynamoDB  Go to the IAM Console. Select Roles from the left menu and click Create role.  Under Trusted entity type, select AWS service, and for Use case, choose Lambda.  In Permissions policies, search for and attach the AmazonDynamoDBFullAccess policy, then click Next.   (You can also create a custom policy if you want stricter access control.)\n In the \u0026ldquo;Name, review, and create\u0026rdquo; section, give your role a name, e.g., lambda-dynamodb-role.  Click Create role to finish.   Create IAM Role for Lambda Functions that Interact with Both DynamoDB and S3 Unlike functions that only interact with DynamoDB, some functions (like the delete image function) need permission to delete images from S3.\nYou’ll create a separate IAM Role with access to both DynamoDB and S3.\n Again, go to the IAM Console, choose Roles from the left menu and click Create role.  Under Trusted entity type, select AWS service, and for Use case, choose Lambda.  In Permissions policies, attach:   AmazonDynamoDBFullAccess AmazonS3FullAccess   Then click Next   (You can also create custom policies to enforce least-privilege access.)\n In the \u0026ldquo;Name, review, and create\u0026rdquo; section, name your role, e.g., lambda-dynamodb-and-s3-role.  Click Create role to complete the process.   Role Reusability This IAM Role can be reused across multiple Lambda functions that interact with DynamoDB, including:\n Create or update operations Deleting records Querying detail by ID or listing items  In a production environment, it’s recommended to apply the principle of least privilege by creating custom IAM policies with specific actions only (e.g., PutItem, GetItem, DeleteItem) instead of using full access.\n\r title: \u0026ldquo;Create IAM Role for Lambda Function\u0026rdquo; date: \u0026ldquo;r Sys.Date()\u0026rdquo; weight: 1 chapter: false pre: \u0026quot; 4.1. \u0026quot; Overview Before deploying any Lambda function, you must create an IAM Role – which grants permission for the Lambda function to access other AWS services, such as reading/writing data in DynamoDB.\nIn this section, we’ll grant appropriate permissions.\nIAM (Identity and Access Management) acts as a permission layer, allowing Lambda to securely operate in your AWS environment.\n Steps to Create IAM Role for Lambda Functions Working with DynamoDB  Go to the IAM Console. Select Roles from the left menu and click Create role.  Under Trusted entity type, select AWS service, and for Use case, choose Lambda.  In Permissions policies, search for and attach the AmazonDynamoDBFullAccess policy, then click Next.   (You can also create a custom policy if you want stricter access control.)\n In the \u0026ldquo;Name, review, and create\u0026rdquo; section, give your role a name, e.g., lambda-dynamodb-role.  Click Create role to finish.   Create IAM Role for Lambda Functions that Interact with Both DynamoDB and S3 Unlike functions that only interact with DynamoDB, some functions (like the delete image function) need permission to delete images from S3.\nYou’ll create a separate IAM Role with access to both DynamoDB and S3.\n Again, go to the IAM Console, choose Roles from the left menu and click Create role.  Under Trusted entity type, select AWS service, and for Use case, choose Lambda.  In Permissions policies, attach:   AmazonDynamoDBFullAccess AmazonS3FullAccess   Then click Next   (You can also create custom policies to enforce least-privilege access.)\n In the \u0026ldquo;Name, review, and create\u0026rdquo; section, name your role, e.g., lambda-dynamodb-and-s3-role.  Click Create role to complete the process.   Role Reusability This IAM Role can be reused across multiple Lambda functions that interact with DynamoDB, including:\n Create or update operations Deleting records Querying detail by ID or listing items  In a production environment, it’s recommended to apply the principle of least privilege by creating custom IAM policies with specific actions only (e.g., PutItem, GetItem, DeleteItem) instead of using full access.\n\r"
},
{
	"uri": "/2-image-upload-and-resize/2.1-upload-original-image/2.1.1-create-s3-bucket/",
	"title": "Create S3 Bucket",
	"tags": [],
	"description": "",
	"content": "Objective In this step, you will create an S3 Bucket to store original images uploaded from the frontend. This serves as the foundation for image processing in later steps.\n Steps to Manually Create an S3 Bucket  Go to the AWS S3 Console and click Create bucket.  In the General configuration section, fill in the following details:    AWS Region: Choose a single AWS region to deploy all resources (Lambda, S3, DynamoDB, etc.) to reduce latency and simplify permission configuration\n(e.g., Asia Pacific (Singapore) ap-southeast-1)\n  Bucket type: General purpose (default)\n  Bucket name: upload-originals-fcj\n  Note: Bucket names must be globally unique and cannot contain spaces or special characters.\n\r In the Block Public Access settings section, leave the default settings (all checkboxes selected) to prevent public access.\n Since this bucket stores original images, access will be handled via Presigned URLs, so public access is not needed.\n   Scroll down and click Create bucket to complete the process.\n  After creating the bucket, open it and go to the Permissions tab.  Scroll down to the Cross-origin resource sharing (CORS) section. Click Edit and paste the following configuration:  [ { \u0026#34;AllowedHeaders\u0026#34;: [ \u0026#34;*\u0026#34; ], \u0026#34;AllowedMethods\u0026#34;: [ \u0026#34;PUT\u0026#34;, \u0026#34;GET\u0026#34;, \u0026#34;POST\u0026#34; ], \u0026#34;AllowedOrigins\u0026#34;: [ \u0026#34;*\u0026#34; ], \u0026#34;ExposeHeaders\u0026#34;: [ \u0026#34;ETag\u0026#34; ] } ] "
},
{
	"uri": "/2-image-upload-and-resize/2.2-resize-image/2.2.1-create-s3-buckets/",
	"title": "Create S3 Bucket",
	"tags": [],
	"description": "",
	"content": "Objective In this step, you will create an S3 Bucket to store images that have been resized by the Lambda function.\nThis bucket is used to separate original images from optimized ones, ensuring both performance and security for the frontend.\n Steps to Manually Create an S3 Bucket  Go to the AWS S3 Console and click Create bucket.  Under General configuration, enter the following details:   Bucket name: resize-image-fcj AWS Region: Use the same region as other services (Lambda, DynamoDB, etc.) – e.g., Asia Pacific (Singapore) ap-southeast-1 Bucket type: General purpose (default)  Note: Bucket names must be globally unique and must not contain spaces or special characters.\n\rIn the Block Public Access settings section:   Uncheck Block all public access Check the box I acknowledge that the current settings might result in this bucket and the objects within becoming public   Since the resized images will be displayed directly in the frontend (browser), public access is required.\n Finally, scroll down and click Create bucket to complete the process.   Once the bucket is created, you need to attach a policy to allow public access to images stored in it.\nOpen the newly created S3 bucket, go to the Permissions tab, then click Edit under Bucket policy.  Paste the following policy into the Policy editor.  Scroll down and click Save changes to finish.   Result Once completed, you will see the resize-image-fcj bucket appear in the list. This bucket will be used by Lambda functions to store resized and optimized images.\n"
},
{
	"uri": "/1-introduce/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Overview of Serverless Architecture Serverless is a cloud computing model that lets you run applications without managing servers, operating systems, or infrastructure. Amazon Web Services automatically handles:\n Provisioning compute when there’s a request or event Automatic scaling to meet any request volume, from one to thousands Shutting down idle resources to save costs Hardware maintenance and security patching  Benefits of going serverless\n Reduced operational overhead: no need to manage servers or set up auto-scaling Faster deployments: update your code and deploy instantly Pay-per-use billing: charged only for the number of invocations and execution time (milliseconds), plus storage fees based on read/write capacity and GB-months Event-driven architecture: easily integrate with services like S3, DynamoDB Streams, and API Gateway  Reference: AWS Serverless Computing Overview\n Services Used in This Workshop AWS Lambda  A serverless compute service that runs your code in response to events (event-driven). Automatically scales with incoming events; you pay only for invocations and execution duration (in milliseconds). Supports multiple languages (Node.js, Python, C#, Java, Go, etc.) and lets you package dependencies as deployment packages or container images. Natively integrates with other AWS services (S3, DynamoDB, Kinesis, SNS, SQS, API Gateway, and more). Offers versioning and aliases to enable blue/green or canary deployments.  Documentation: AWS Lambda Developer Guide\nAmazon API Gateway  A fully managed service to create, publish, secure, and monitor RESTful or WebSocket APIs. Supports two API types: REST APIs (feature-rich) and HTTP APIs (lower latency, lower cost). Provides mapping templates to transform request and response payloads, enabling integration with Lambda, HTTP endpoints, or VPC Links. Built-in support for CORS, throttling, caching, and AWS WAF for API protection. Supports authentication via Amazon Cognito User Pools, IAM roles, or custom Lambda authorizers.  Documentation: Amazon API Gateway Developer Guide\nAmazon S3  Durable (99.999999999%) object storage with virtually unlimited scalability. Multiple storage classes (Standard, Intelligent-Tiering, Infrequent Access, Glacier) to optimize costs. Features versioning, lifecycle policies (automatic deletion or transition), and event notifications. Provides read-after-write consistency for new PUTs and eventual consistency for overwrite PUTs and DELETEs. Ideal for storing static assets, backups, logs, media files, and big data.  Documentation: Amazon S3 User Guide\nAmazon DynamoDB  Fully managed NoSQL key-value and document database with single-digit millisecond latency. Automatically scales throughput (Read/Write Capacity Units) and storage as needed. Supports eventual consistency (default) and optional strong consistency. Offers DynamoDB Streams for change data capture, TTL for automatic item expiration, and ACID transactions. Distributed architecture based on partition keys for high scalability and reliability.  Documentation: Amazon DynamoDB Developer Guide\nS3 Static Website Hosting  Host static websites (HTML, CSS, JavaScript) directly from an S3 bucket. Configure a bucket as a website endpoint (e.g., http://\u0026lt;bucket-name\u0026gt;.s3-website-\u0026lt;region\u0026gt;.amazonaws.com). Supports custom domains via Amazon Route 53 and HTTPS through Amazon CloudFront. Perfect for SPAs, landing pages, and static documentation.  Documentation: Hosting a Static Website on Amazon S3\nAmazon Cognito  Authentication and authorization service for web and mobile applications. User Pools: user directory with built-in sign-up/sign-in APIs, multi-factor authentication (MFA), and social identity providers. Identity Pools (Federated Identities): issue temporary AWS credentials to authenticated users from User Pools, social providers, or SAML/OIDC. Supports OAuth 2.0, OpenID Connect, and JWT tokens to secure API Gateway and backend services. Integrates with Lambda triggers to customize workflows (e.g., pre-/post-authentication, email/phone verification).  Documentation: Amazon Cognito Developer Guide\n"
},
{
	"uri": "/",
	"title": "Serverless Web Application Management System on AWS",
	"tags": [],
	"description": "",
	"content": " Serverless Web Application Management System on AWS Overview In today’s digital era, developing and operating web applications must meet various requirements for performance, cost-efficiency, and scalability. Traditional models using physical servers or EC2 instances often entail high operational costs, limited flexibility, and complex system administration, which poses challenges for many small and medium-sized enterprises (SMEs) in rapidly deploying software solutions.\nThe Serverless solution on AWS enables building systems without managing servers, paying only for actual resource usage. With this architecture, developers can fully focus on business logic while AWS handles auto-scaling, maintenance, and monitoring.\nThis system includes the following core components:\n Amazon API Gateway: manages RESTful endpoints AWS Lambda: handles serverless business logic Amazon DynamoDB: high-performance NoSQL data storage Amazon S3: stores original and resized images Amazon Cognito: handles authentication, authorization, and user management S3 + CloudFront: deploys static frontend with global fast delivery  The system is designed to:\n Reduce operational costs by 60–70% compared to EC2 Automatically scale with actual traffic Provide a secure and flexible product management interface Enable fast image uploads and automatic image resizing  Serverless Architecture in the Workshop Below is the overall architecture diagram illustrating how AWS services interact within this workshop system:\nMain Sections  Introduction Image Upload and Resizing Writing Data to Amazon DynamoDB Deploying Lambda Functions Configuring API Gateway Setting Up Cognito UserPool Authentication and Authorization Deploying the Frontend Final Result Verification Clean Up Resources   title : \u0026ldquo;Serverless Web Application Management System on AWS\u0026rdquo; date : \u0026ldquo;r Sys.Date()\u0026rdquo; weight : 1 chapter : false Serverless Web Application Management System on AWS Overview In today’s digital era, developing and operating web applications must meet various requirements for performance, cost-efficiency, and scalability. Traditional models using physical servers or EC2 instances often entail high operational costs, limited flexibility, and complex system administration, which poses challenges for many small and medium-sized enterprises (SMEs) in rapidly deploying software solutions.\nThe Serverless solution on AWS enables building systems without managing servers, paying only for actual resource usage. With this architecture, developers can fully focus on business logic while AWS handles auto-scaling, maintenance, and monitoring.\nThis system includes the following core components:\n Amazon API Gateway: manages RESTful endpoints AWS Lambda: handles serverless business logic Amazon DynamoDB: high-performance NoSQL data storage Amazon S3: stores original and resized images Amazon Cognito: handles authentication, authorization, and user management S3 + CloudFront: deploys static frontend with global fast delivery  The system is designed to:\n Reduce operational costs by 60–70% compared to EC2 Automatically scale with actual traffic Provide a secure and flexible product management interface Enable fast image uploads and automatic image resizing  Serverless Architecture in the Workshop Below is the overall architecture diagram illustrating how AWS services interact within this workshop system:\nMain Sections  Introduction Image Upload and Resizing Writing Data to Amazon DynamoDB Deploying Lambda Functions Configuring API Gateway Setting Up Cognito UserPool Authentication and Authorization Deploying the Frontend Final Result Verification Clean Up Resources  "
},
{
	"uri": "/2-image-upload-and-resize/2.1-upload-original-image/",
	"title": "Upload Original Image",
	"tags": [],
	"description": "",
	"content": "Overview The first step in the image processing workflow is to upload the original image from the frontend to AWS S3, in a secure and efficient manner.\nTo achieve this, you will use an AWS Lambda function to generate a Presigned URL – a temporary, secure link that allows the client to upload the image directly to S3 without routing through a backend server or exposing sensitive credentials.\nAt this stage, resizing or metadata processing is not handled – the goal is solely to ensure that the original image is safely stored in S3.\n\r Main Steps  Create S3 Buckets Create IAM Role Create PresignedURL Lambda Function  "
},
{
	"uri": "/7-authentication-and-authorization/7.2-authorization-with-cognito-groups/",
	"title": "Configure Cognito Group-Based Authorization",
	"tags": [],
	"description": "",
	"content": " Overview Cognito supports user authorization by group using User Pool Groups. When a user logs in and belongs to a specific group, that group information is attached to the JWT token (in the cognito:groups claim). This allows us to check authorization either in the backend (Lambda) or directly in API Gateway.\nMain Content Create Cognito User Pool Groups   Go to Amazon Cognito Console. Select the existing User Pool. Go to Group and select Create group\n  In Group information, enter the following:\n   Group name: admin   Then select Create group  Create another group user:   Group name: user   After creating the admin and user groups, assign users to the respective group\n  In the users list, select the user to add to a group\n  In the user detail page, choose Add user to group  Select the group to assign, for example: user  Once completed, you will see the result as:  Create an admin user for the system and assign to the admin group  Open Postman and create a user account:  After creation, go to the newly created user in AWS Cognito:  In the User attributes tab, click Edit to verify email:  Check Mark email as verified:  Finally, click Confirm user to activate the account:  Add the admin user to the admin group  Configure group-based authorization in Lambda functions For existing Lambda functions, you now need to configure them via AWS Console to read the group from JWT token inside Lambda\n\rSample code for group-based authorization from token const claims = event.requestContext.authorizer?.jwt?.claims || event.requestContext.authorizer?.claims || {}; const groups = Array.isArray(claims[\u0026#34;cognito:groups\u0026#34;]) ? claims[\u0026#34;cognito:groups\u0026#34;] : claims[\u0026#34;cognito:groups\u0026#34;] ? [claims[\u0026#34;cognito:groups\u0026#34;]] : []; if (!groups.includes(\u0026#34;admin\u0026#34;)) { return { statusCode: 403, body: JSON.stringify({ error: \u0026#34;You do not have permission\u0026#34; }), }; } Configure authorization for product For create-product-lambda function   Go to AWS Lambda Console, select the Lambda function to configure, e.g., create-product\n  In the Lambda code screen, add the code to the top of index.mjs file, then click Deploy\n  For update-product-lambda function   Go to AWS Lambda Console, select the Lambda function to configure, e.g., create-product\n  In the Lambda code screen, add the code to the top of index.mjs file, then click Deploy\n  For delete-product-lambda function   Go to AWS Lambda Console, select the Lambda function to configure, e.g., create-product\n  In the Lambda code screen, add the code to the top of index.mjs file, then click Deploy\n  Configure authorization for category For create-category-lambda function   Go to AWS Lambda Console, select the Lambda function to configure, e.g., create-category\n  In the Lambda code screen, add the code to the top of index.mjs file, then click Deploy\n  For update-category-lambda function   Go to AWS Lambda Console, select the Lambda function to configure, e.g., update-category\n  In the Lambda code screen, add the code to the top of index.mjs file, then click Deploy\n  For delete-category-lambda function   Go to AWS Lambda Console, select the Lambda function to configure, e.g., delete-category\n  In the Lambda code screen, add the code to the top of index.mjs file, then click Deploy\n  "
},
{
	"uri": "/2-image-upload-and-resize/2.1-upload-original-image/2.1.2-create-iam-role/",
	"title": "Create IAM Role for Lambda GetPresignedUrl",
	"tags": [],
	"description": "",
	"content": "Objective In this section, you will create an IAM Role for the Lambda function GetPresignedUrl.\nThis Lambda function will generate a Presigned URL to upload original images to S3 using the PutObject permission.\nTo follow the principle of least privilege, we will create a custom IAM Policy that only grants write permission to the specific bucket created earlier — upload-originals-fcj.\n Steps to Create a Custom IAM Policy for the Role  Go to the IAM Console, select Policies from the left menu, then click Create policy.  In the Create policy interface, switch to the JSON tab, paste the following snippet, and replace \u0026lt;your-bucket-name\u0026gt; with your actual bucket name\n– e.g., upload-originals-fcj.  { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::\u0026lt;your-bucket-name\u0026gt;/*\u0026#34; } ] } Click Next, and under the Policy details section, fill in the following:   Policy name: S3PutOriginalImagePolicy Description (optional): S3PutOriginalImagePolicy  Scroll down and click Create policy to finish.   Steps to Create IAM Role  Next, go to the IAM Console, select Roles from the left menu, and then click Create role.  Under Trusted entity type, choose AWS service, and for Use case, select Lambda.  In the Permissions policies step, search for and attach the S3PutOriginalImagePolicy, then click Next.  Under the \u0026ldquo;Name, review, and create\u0026rdquo; section, name your role, e.g., lambda-upload-original-role.  Click Create role to complete the process.   Result Once completed, you will see a new IAM Role named lambda-upload-original-role listed in the Roles section of the IAM Console.\nThis role is configured to allow the get-presigned-url Lambda function to upload images directly to the upload-originals-fcj bucket with PutObject permission, following the least privilege security best practice.\n"
},
{
	"uri": "/2-image-upload-and-resize/2.2-resize-image/2.2.2-create-iam-role/",
	"title": "Create IAM Role for Lambda ResizeImage",
	"tags": [],
	"description": "",
	"content": "Objective In this section, you will create an IAM Role specifically for the resize-image Lambda function.\nThis function performs the following tasks:\n Reads original images from the S3 bucket upload-originals-fcj Resizes the images and writes the results to the S3 bucket resize-image-fcj  To follow the \u0026ldquo;Least Privilege\u0026rdquo; principle, we will create a custom IAM Policy that only grants permission to read from the original image bucket and write to the resized image bucket.\n Create Custom IAM Policy for Lambda Resize Steps to Create Custom IAM Policy  Go to the IAM Console, select Policies from the left-hand menu, then click Create policy.  Switch to the JSON tab and paste the following configuration:  { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowListAndGetOnSource\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:GetObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::\u0026lt;your-original-bucket-name\u0026gt;\u0026#34;, \u0026#34;arn:aws:s3:::\u0026lt;your-original-bucket-name\u0026gt;/*\u0026#34; ] }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowPutOnDestination\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::\u0026lt;your-resized-bucket-name\u0026gt;/*\u0026#34; } ] } Note: your-original-bucket-name refers to the bucket used for storing original images, and your-resized-bucket-name refers to the bucket used for storing resized images.\n\r Click Next, and under the Policy details section, enter the following:   Policy name: ResizeImageLambdaS3Policy Description (optional): ResizeImageLambdaS3Policy  Scroll down and click Create policy to finish.   Steps to Create IAM Role  Next, go to the IAM Console, select Roles from the left-hand menu, then click Create role.   Under Trusted entity type, choose AWS service, and in the Use case, select Lambda.\n  In the Permissions policies step, search for and attach the ResizeImageLambdaS3Policy (you may see S3PutOriginalImagePolicy in the UI but skip it if unnecessary).\n  Confirm the correct policy ResizeImageLambdaS3Policy is selected and click Next.  In the Name, review, and create step, name the role – for example: lambda-resize-image-role.  Click Create role to complete.   Result Once completed, you will see a new IAM Role named lambda-resize-image-role listed under the Roles section of the IAM Console.\nThis role is configured to allow the resize-image Lambda function to upload images directly to the resize-image-fcj bucket using PutObject permission, in compliance with the least privilege security principle.\n"
},
{
	"uri": "/4-deploy-lambda-function/4.2-create-or-update-lambda-function/",
	"title": "Create or Update Lambda Functions",
	"tags": [],
	"description": "",
	"content": "Overview In this section, we will implement the following Lambda functions:\n Two Lambda functions: create-product, update-product – used to create or update product data in DynamoDB. Two Lambda functions: create-category, update-category – used to create or update category data in DynamoDB.  These functions are written in Node.js 22.x and use access permissions via a pre-created IAM Role.\n Create the create-product Lambda Function in AWS Console  Go to AWS Lambda Console, and click Create function.  On the Create function screen, select Author from scratch. In the Basic information section, enter:   Function name: create-product Runtime: Node.js 22.x Architecture: x86_64  AWS Lambda supports multiple runtimes including Java, .NET, Python, and Node.js.\nHere, we use Node.js 22.x – the latest version with better performance and modern syntax compared to Node.js 18.x.\n\rUnder Change default execution role:   Select: Use an existing role Choose the IAM Role created earlier, e.g., lambda-dynamodb-role Click Create function  Currently, Lambda doesn\u0026rsquo;t support inline ESM editing for Node.js 22.x.\nYou need to prepare the code and dependencies locally, then zip and upload manually.\n\r Option 1: Use Prebuilt .zip File (Quick and Easy)  Recommended if you want to deploy quickly without additional setup. Provided by the workshop.\n   Download the prebuilt .zip file here: create-product-lambda.zip\n  Then:\n   Go to the create-product Lambda function Under the Code tab, click Upload from → .zip file   Choose the create-product-lambda.zip file you just downloaded  After uploading, click Deploy  Set environment variables:   REGION: your AWS region TABLE_NAME: your DynamoDB table name RESIZED_BUCKET: S3 bucket name for resized images  Make sure these values match your actual resources; otherwise, the Lambda will not work correctly.\nIf you edit code directly in the AWS Lambda Console, don’t forget to click Deploy afterward.\n\r Option 2: Build and Upload Locally   Download the source code here: create-product-source.zip\n  Follow build instructions in: Tạo hàm Lambda GetPresignedUrl\n   Create the update-product Lambda Function Same steps as create-product:\n Function name: update-product Runtime: Node.js 22.x Architecture: x86_64 IAM Role: lambda-dynamodb-role    Download prebuilt .zip: update-product-lambda.zip\n  Upload to Lambda\n  Click Deploy  Set environment variables:   REGION TABLE_NAME RESIZED_BUCKET  If you edit code directly in the AWS Lambda Console, don’t forget to click Deploy afterward.\n\rOptional:\nDownload the source: update-product-source.zip\n Create the create-category Lambda Function Same steps as above:\n Function name: create-category Runtime: Node.js 22.x Architecture: x86_64 IAM Role: lambda-dynamodb-role    Download .zip: create-category-lambda.zip\n  Upload the .zip file to the create-category Lambda\n  Set environment variables:   REGION TABLE_NAME  Optional:\nDownload the source: create-category-source.zip\nBuild instructions: GetPresignedUrl Lambda Guide\n Create the update-category Lambda Function Same steps as above:\n Function name: update-category Runtime: Node.js 22.x Architecture: x86_64 IAM Role: lambda-dynamodb-role    Download .zip: update-category-lambda.zip\n  Upload the .zip file to the update-category Lambda\n  Set environment variables:   REGION TABLE_NAME  Optional:\nDownload the source: update-category-source.zip\nBuild instructions: GetPresignedUrl Lambda Guide title: \u0026ldquo;Create or Update Lambda Functions\u0026rdquo; date: \u0026ldquo;r Sys.Date()\u0026rdquo; weight: 2 chapter: false pre: \u0026quot; 4.2. \u0026quot; Overview In this section, we will implement the following Lambda functions:\n Two Lambda functions: create-product, update-product – used to create or update product data in DynamoDB. Two Lambda functions: create-category, update-category – used to create or update category data in DynamoDB.  These functions are written in Node.js 22.x and use access permissions via a pre-created IAM Role.\n Create the create-product Lambda Function in AWS Console  Go to AWS Lambda Console, and click Create function.  On the Create function screen, select Author from scratch. In the Basic information section, enter:   Function name: create-product Runtime: Node.js 22.x Architecture: x86_64  AWS Lambda supports multiple runtimes including Java, .NET, Python, and Node.js.\nHere, we use Node.js 22.x – the latest version with better performance and modern syntax compared to Node.js 18.x.\n\rUnder Change default execution role:   Select: Use an existing role Choose the IAM Role created earlier, e.g., lambda-dynamodb-role Click Create function  Currently, Lambda doesn\u0026rsquo;t support inline ESM editing for Node.js 22.x.\nYou need to prepare the code and dependencies locally, then zip and upload manually.\n\r Option 1: Use Prebuilt .zip File (Quick and Easy)  Recommended if you want to deploy quickly without additional setup. Provided by the workshop.\n   Download the prebuilt .zip file here: create-product-lambda.zip\n  Then:\n   Go to the create-product Lambda function Under the Code tab, click Upload from → .zip file   Choose the create-product-lambda.zip file you just downloaded  After uploading, click Deploy  Set environment variables:   REGION: your AWS region TABLE_NAME: your DynamoDB table name RESIZED_BUCKET: S3 bucket name for resized images  Make sure these values match your actual resources; otherwise, the Lambda will not work correctly.\nIf you edit code directly in the AWS Lambda Console, don’t forget to click Deploy afterward.\n\r Option 2: Build and Upload Locally   Download the source code here: create-product-source.zip\n  Follow build instructions in: Tạo hàm Lambda GetPresignedUrl\n   Create the update-product Lambda Function Same steps as create-product:\n Function name: update-product Runtime: Node.js 22.x Architecture: x86_64 IAM Role: lambda-dynamodb-role    Download prebuilt .zip: update-product-lambda.zip\n  Upload to Lambda\n  Click Deploy  Set environment variables:   REGION TABLE_NAME RESIZED_BUCKET  If you edit code directly in the AWS Lambda Console, don’t forget to click Deploy afterward.\n\rOptional:\nDownload the source: update-product-source.zip\n Create the create-category Lambda Function Same steps as above:\n Function name: create-category Runtime: Node.js 22.x Architecture: x86_64 IAM Role: lambda-dynamodb-role    Download .zip: create-category-lambda.zip\n  Upload the .zip file to the create-category Lambda\n  Set environment variables:   REGION TABLE_NAME  Optional:\nDownload the source: create-category-source.zip\nBuild instructions: GetPresignedUrl Lambda Guide\n Create the update-category Lambda Function Same steps as above:\n Function name: update-category Runtime: Node.js 22.x Architecture: x86_64 IAM Role: lambda-dynamodb-role    Download .zip: update-category-lambda.zip\n  Upload the .zip file to the update-category Lambda\n  Set environment variables:   REGION TABLE_NAME  Optional:\nDownload the source: update-category-source.zip\nBuild instructions: GetPresignedUrl Lambda Guide\n"
},
{
	"uri": "/5-config-api-gateway/5.2-create-resource-and-method/",
	"title": "Create Resources and Corresponding Methods",
	"tags": [],
	"description": "",
	"content": "Overview After creating the API Gateway (eshop-fcj), the next step is to define the resources and configure methods to connect with the previously created Lambda functions such as creating a product, fetching data, deleting items, etc.\n Steps to Create Resources and Methods Create resource for products to link with corresponding product-related Lambda functions  Open the API Gateway Console, access the eshop-fcj API and click Create Resource.  In Resource details:   Resource Path: / Resource Name: products  Click Create Resource  Similarly, you can create the following resources:\n For categories:  Resource Path: / Resource Name: categories     For image uploads:  Resource Path: / Resource Name: uploads     Add Method for a Resource For example, to add a POST method to /products:\n Select the /products resource in the Resource Tree, then click Create Method  In the Method details, fill out the following:   Method type: POST Integration type: Lambda function Lambda function: Select the region and your deployed Lambda function, e.g., create-product Enable Lambda proxy integration  Note: In this project, all APIs receive JSON body input, so Lambda Proxy Integration is required.\n\rScroll down and click Create method   To create a GET method with path parameter like /products/{id}:\n Inside the eshop-fcj API, click Create Resource  In Resource details:   Resource Path: /products Resource Name: {id}  Then click Create Resource\nSelect the /products resource and then the {id} sub-resource, click Create Method  In Method details, fill out the following:   Method type: GET Integration type: Lambda function Enable Lambda proxy integration Lambda function: e.g., get-product  Scroll down and click Create method   Repeat the above steps for all other resources and methods in the following table:    Resource Path Resource Name Method Functionality Description Lambda Function     / products POST Create a new product create-product   / products GET Get all products get-product   /products {id} GET Get a product by ID get-product   /products {id} DELETE Delete a product by ID delete-product   / categories POST Create product category create-category   / categories GET Get all categories get-category   /categories {id} GET Get category by ID get-category   /categories {id} DELETE Delete category by ID delete-category   / upload-image POST Generate image upload URL get-presigned-url    You must repeat the above steps for each resource and method as shown in the table in order for the frontend to be able to call those APIs.\n\r The final result will look like this: "
},
{
	"uri": "/2-image-upload-and-resize/",
	"title": "Image Upload and Optimization",
	"tags": [],
	"description": "",
	"content": "Overview Image processing is a common requirement in modern systems such as social networks, e-commerce platforms, and user profile management.\nHowever, to ensure images are uploaded securely and then automatically processed and optimized, the system should include:\n A backend-less upload process (to reduce server load) Automated processing using S3 Event Trigger + AWS Lambda Clear separation between original and processed images  In this chapter, you will set up a complete workflow to upload images from the client and automatically process them using AWS. Specifically:\n Images are uploaded directly from the frontend to S3 using a Presigned URL Once the upload succeeds, S3 triggers a Lambda function The Lambda function resizes the image and saves it to a different bucket The resized image is then used in the frontend with optimized dimensions and size   Objectives  Enable clients (web/mobile) to upload images directly using a Presigned URL Automatically resize images after upload using Lambda Function + Sharp Save the resized image to a target bucket, ready for use in the frontend   Main Steps  Handle original image upload Resize and optimize the uploaded image  "
},
{
	"uri": "/2-image-upload-and-resize/2.2-resize-image/",
	"title": "Resize Image",
	"tags": [],
	"description": "",
	"content": "Overview After the original image has been successfully uploaded to S3, the next step is to automatically optimize the image (resize) to reduce its size and serve it more efficiently on the frontend.\nInstead of letting the frontend handle image resizing (which may be slow, inconsistent, or insecure), we offload this task to the backend. This ensures it is automated, consistent, and controllable by using AWS Lambda in combination with S3 Event Triggers.\nIn this section, you will build a Lambda function responsible for:\n Listening to S3 events (when a new image is uploaded to the original bucket) Downloading the original image, resizing it using the sharp library Saving the resized image to a separate destination S3 bucket  This image processing approach offers several benefits:\n Ensures the frontend always receives optimized images Improves page load speed and user experience Reduces storage and bandwidth costs   Main Topics  Create the Resize Lambda Function Create the S3 Buckets Create the IAM Role  "
},
{
	"uri": "/6-setup-cognito-userpool/6.2-test-apis-with-postman/",
	"title": "Test API with Postman",
	"tags": [],
	"description": "",
	"content": "Overview After creating a User Pool and an App Client (without secret), we can test Amazon Cognito APIs via Postman such as:\n Sign up a new user (SignUp) Confirm OTP code (ConfirmSignUp) Sign in and get token (InitiateAuth)   Main Content Note on Calling APIs to Amazon Cognito Amazon Cognito uses a region-based endpoint: https://cognito-idp.\u0026lt;region\u0026gt;.amazonaws.com/\n Example for Singapore: https://cognito-idp.ap-southeast-1.amazonaws.com/\n All requests to Cognito must be distinguished using the ClientId, which is a unique identifier for each App Client under your User Pool.\nHow to get ClientID Common Header Configuration when calling Cognito API\n   Key Value     Content-Type application/x-amz-json-1.1   X-Amz-Target Name of the API you want to call \u0026gt; e.g.: AWSCognitoIdentityProviderService.InitiateAuth, AWSCognitoIdentityProviderService.SignUp    If X-Amz-Target is missing or incorrect → Cognito will return UnknownOperationException or BadRequest.\n\rSign Up User (SignUp)  In the postman interface, enter the following information:    Click Create new request, the + icon on the screen\n  Select method POST and enter the URL: https://cognito-idp.\u0026lt;YOUR-REGION\u0026gt;.amazonaws.com/\n   Replace \u0026lt;YOUR-REGION\u0026gt; with your actual region, e.g.: ap-southeast-1\n   In the Header section:\n  Content-Type: application/x-amz-json-1.1\n  X-Amz-Target: AWSCognitoIdentityProviderService.SignUp\n    Next, go to the body tab, choose raw, and paste the following:  { \u0026#34;ClientId\u0026#34;: \u0026#34;YOUR_APP_CLIENT_ID\u0026#34;, \u0026#34;Username\u0026#34;: \u0026#34;YOUR_USER_NAME\u0026#34;, \u0026#34;Password\u0026#34;: \u0026#34;YOUR_PASS_WORD\u0026#34;, \u0026#34;UserAttributes\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;email\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;YOUR_EMAIL\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;name\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;YOUR_FULL_NAME\u0026#34; } ] } Wait for the response in the body in JSON format.  Check that the account has been added under users.   Check the email you registered with. You will receive a verification code (OTP) from Cognito to proceed with account confirmation in the next step.   Confirm User (ConfirmSignUp)  In the Postman interface, enter the following information:    Click Create new request, the + icon on the screen\n  Choose method POST and enter the URL: https://cognito-idp.\u0026lt;YOUR-REGION\u0026gt;.amazonaws.com/\n   Replace \u0026lt;YOUR-REGION\u0026gt; with your actual region, e.g.: ap-southeast-1\n   In the Header section:\n  Content-Type: application/x-amz-json-1.1\n  X-Amz-Target: AWSCognitoIdentityProviderService.ConfirmSignUp\n    Next, go to the body tab, choose raw, and paste the following:  { \u0026#34;ClientId\u0026#34;: \u0026#34;YOUR_APP_CLIENT_ID\u0026#34;, \u0026#34;Username\u0026#34;: \u0026#34;YOUR_USER_NAME\u0026#34;, \u0026#34;ConfirmationCode\u0026#34;: \u0026#34;YOUR_CODE\u0026#34; } Wait for the response in the body in JSON format. The response will include a SESSION.  Check if the account has been successfully confirmed.   User Authentication (InitiateAuth)  In the Postman interface, enter the following information:    Click Create new request, the + icon on the screen\n  Choose method POST and enter the URL: https://cognito-idp.\u0026lt;YOUR-REGION\u0026gt;.amazonaws.com/\n   Replace \u0026lt;YOUR-REGION\u0026gt; with your actual region, for example: ap-southeast-1\n   In the Header section:\n  Content-Type: application/x-amz-json-1.1\n  X-Amz-Target: AWSCognitoIdentityProviderService.InitiateAuth\n    Next, go to the body tab, choose raw, and paste the following:  { \u0026#34;ClientId\u0026#34;: \u0026#34;YOUR_APP_CLIENT_ID\u0026#34;, \u0026#34;AuthFlow\u0026#34;: \u0026#34;USER_PASSWORD_AUTH\u0026#34;, \u0026#34;AuthParameters\u0026#34;: { \u0026#34;USERNAME\u0026#34;: \u0026#34;YOUR_USER_NAME\u0026#34;, \u0026#34;PASSWORD\u0026#34;: \u0026#34;YOUR_PASS_WORD\u0026#34; } } Wait for the response in the body in JSON format. It will include important information such as: AccessToken, IdToken, ExpiresIn, RefreshToken, and TokenType.  "
},
{
	"uri": "/2-image-upload-and-resize/2.1-upload-original-image/2.1.3-create-presignedurl-lambda-function/",
	"title": "Create Lambda Function GetPresignedUrl",
	"tags": [],
	"description": "",
	"content": "Overview In this step, you will deploy a Lambda function named get-presigned-url, whose purpose is to generate a Presigned URL that allows the frontend to upload images directly to the S3 bucket for original images.\nThis function is written in Node.js 22.x and uses an IAM Role (created earlier) to access S3.\n Create the get-presigned-url Lambda Function via AWS Console  Go to the AWS Lambda Console, select Functions, then click Create function.  On the Create function screen, choose Author from scratch, and in the Basic information section, enter:   Function name: get-presigned-url Runtime: Node.js 22.x Architecture: x86_64  Currently, AWS Lambda supports several languages including Java, .NET, Python, Node.js,\u0026hellip;\nIn this tutorial, we use Node.js 22.x — the latest version with higher performance and modern syntax compared to Node.js 18.x.\n\rIn the Change default execution role section:   Choose: Use an existing role Then select the IAM Role created earlier, e.g., lambda-upload-original-role Finally, click Create function  Once created, Lambda will redirect to the code editor screen.\n Deploy Lambda Source Code for get-presigned-url Once the function is created, Lambda will open the code editor.\nCurrently, Node.js 22.x does not support direct editing with ESM (import/export) syntax in the console.\nTherefore, you need to prepare the source code and dependencies locally, then zip and upload manually.\n\r Prepare Source Code and Dependencies You can choose one of the following two methods to deploy the Lambda function:\n Option 1: Use Pre-built ZIP File (Quick and Easy)  Recommended for quick deployment without extra setup — this workshop provides a pre-built version.\n   Download the pre-built .zip file here: get-presigned-url-lambda.zip\n  After downloading the ZIP file:\n   Go to AWS Lambda, select the get-presigned-url function In the Code section, click Upload from, then select .zip file   Select the downloaded get-presigned-url-lambda.zip  After uploading, click Deploy   Option 2: Build from Source Code Manually  For users who want to learn and build from scratch.\n   Download the source code here: get-presigned-url-source.zip\n  After extracting, you’ll see the following files:\n   index.mjs: contains the Lambda logic package.json: declares required libraries  Open a terminal or command prompt inside the folder and run:  npm install  Zip the source code for Lambda   Navigate to the get-presigned-url-source directory Select all the following items: index.mjs, package.json, and node_modules/ Compress them into a single ZIP file named get-presigned-url-lambda.zip   After creating the ZIP file:   Go to AWS Lambda, and select the get-presigned-url function In the Code section, click Upload from, then select .zip file   Select the newly created file: get-presigned-url-lambda.zip   Once the file is uploaded, click Deploy   Verify Lambda Handler: index.handler The Lambda handler must follow the format: \u0026lt;FILENAME\u0026gt;.\u0026lt;FUNCTION_NAME\u0026gt;\nIn this case: index.handler\n\r"
},
{
	"uri": "/2-image-upload-and-resize/2.2-resize-image/2.2.3-create-resize-lambda-function/",
	"title": "Create Lambda Function Resize",
	"tags": [],
	"description": "",
	"content": "Overview In this step, you will deploy a Lambda function named resize-image, with the purpose of automatically resizing and optimizing images every time a new image is uploaded to S3.\nThis helps the frontend load images faster, reduce bandwidth usage, and improve rendering performance.\nThe function is written in Node.js 22.x and uses an IAM Role created in the previous step to access S3.\n Create Lambda Function resize-image via AWS Console  Go to the AWS Lambda Console, then click Create function.  On the Create function screen, choose Author from scratch, and fill in the following under Basic information:   Function name: resize-image Runtime: Node.js 22.x Architecture: x86_64  AWS Lambda currently supports various runtimes including Java, .NET, Python, Node.js,\u0026hellip;\nIn this tutorial, we use Node.js 22.x — the latest version with better performance and modern syntax compared to Node.js 18.x.\n\rUnder Change default execution role:   Select: Use an existing role Then choose the IAM Role you created, e.g., lambda-resize-image-role Finally, click Create function  Lambda will then redirect to the function editor interface.\n Deploy Source Code for Lambda resize-image You can choose one of the following two methods to deploy the Lambda:\n Option 1: Use Pre-built ZIP File (Quick \u0026amp; Easy)  Recommended for quick deployment without setup. The pre-built package is ready for use.\n   Download the pre-built .zip here: resize-image.zip\n  Once downloaded:\n   Go to AWS Lambda, select the resize-image function In the Code section, click Upload from, then choose .zip file   Select the resize-image-lambda.zip you downloaded  After uploading, click Deploy  Verify the handler is: index.handler\nLambda handlers follow the format: \u0026lt;FILENAME\u0026gt;.\u0026lt;FUNCTION_NAME\u0026gt;\n\rThen, scroll down for the section Configure S3 Trigger for Lambda resize-image\n Option 2: Manually Build Source Code  For those who want to learn by building from scratch.\n   Download the sample source code here: resize-image-source.zip\n  After extracting, you’ll see:\n   index.mjs: Lambda logic package.json: Declares required dependencies  Note:\nThis workshop uses Sharp for image processing.\nSince it\u0026rsquo;s a native module, it must be compiled for the target runtime (Amazon Linux 2).\nIf you install sharp on Windows/macOS and deploy it to Lambda, it will throw an error like:\nError: Cannot find module 'sharp'\nYou must use Docker with AWS Lambda\u0026rsquo;s official image to install dependencies.\n\rOpen PowerShell in the source folder and run:  docker run --rm -v \u0026#34;${PWD}:/app\u0026#34; -w /app node:22 bash -c \u0026#34;npm install sharp\u0026#34; If using CMD, run:\ndocker run --rm -v \u0026#34;%cd%:/var/task\u0026#34; -w /var/task public.ecr.aws/lambda/nodejs20.x bash -c \u0026#34;npm install sharp\u0026#34;  4. Zip the source code for Lambda  Go to the resize-image-source directory Select all files and folders: index.mjs, package.json, node_modules/ Compress them into a file named resize-image-lambda.zip   5. Upload the ZIP file to Lambda  Go to AWS Lambda, select the resize-image function In the Code section, click Upload from, then select .zip file   Select the resize-image-lambda.zip file you just created   6. After the upload is complete, click Deploy Verify the Lambda handler is: index.handler\nThe Lambda handler must follow the format: \u0026lt;FILENAME\u0026gt;.\u0026lt;FUNCTION_NAME\u0026gt;\n\r Configure S3 Trigger for Lambda resize-image After uploading the source code and setting up the resize-image Lambda function, you need to configure a S3 Trigger so that whenever a new image is uploaded, the Lambda function is automatically invoked to perform resizing.\n 1. Go to the resize-image Lambda function page, switch to the Configuration tab → choose Triggers → click Add trigger  2. In Trigger configuration, select the S3 service  3. Fill in the configuration with the following details:   Bucket: Name of the bucket that stores original images, e.g. upload-originals\n  Event types: All object create events\n  Prefix (optional): Only trigger when files are uploaded under a folder, e.g. images/originals/\n  Suffix (optional): Restrict the trigger to specific file extensions\n  Check the box:\n“I acknowledge that using the same S3 bucket for both input and output is not recommended and that this configuration can cause recursive invocations, increased Lambda usage, and increased costs.”\n  Finally, click Add to complete.\n   In this workshop, you will create 2 separate triggers:  Trigger 1: Suffix = .jpg Trigger 2: Suffix = .png  Repeat the same steps to create Trigger 2:\nEach S3 trigger can only specify one Suffix.\nThat’s why in this workshop, you need to create two separate triggers: one for .jpg and one for .png.\n\r Clearly specifying Suffix ensures that Lambda only processes image files, avoiding errors and reducing unnecessary cost.\n  Result Once the triggers are configured, you can verify them from the S3 bucket UI:\n Go to the S3 Console, select the bucket that stores original images (e.g. upload-originals-fcj), then switch to the Properties tab   Scroll down to the Event notifications section — you’ll see a list of event triggers\nEach trigger corresponds to a file suffix like .jpg or .png\n  You will see the event notifications associated with the resize-image Lambda function\n  "
},
{
	"uri": "/4-deploy-lambda-function/4.3-delete-lambda-function/",
	"title": "Delete Product Data with Lambda Function",
	"tags": [],
	"description": "",
	"content": "Overview In this step, we will implement the following Lambda functions:\n A Lambda function named delete-product – used to delete product data from DynamoDB. A Lambda function named delete-category – used to delete category data from DynamoDB.  These functions are written in Node.js 22.x and use a pre-created IAM Role to access DynamoDB.\n Create delete-product Lambda Function on AWS Console  Go to AWS Lambda Console, and click Create function.  On the Create function screen, select Author from scratch, and fill in:   Function name: delete-product Runtime: Node.js 22.x Architecture: x86_64  AWS Lambda currently supports multiple languages like Java, .NET, Python, and Node.js.\nHere, we use Node.js 22.x for better performance and modern syntax support.\n\rUnder Change default execution role:   Choose: Use an existing role Select the role, e.g., lambda-dynamodb-and-s3-role Click Create function  Lambda currently does not support inline editing with ESM (import/export) in Node.js 22.x.\nYou need to prepare the code locally and upload as a ZIP file.\n\r Option 1: Use Prebuilt .zip File  Recommended for quick deployment without local setup. Provided by the workshop.\n   Download prebuilt ZIP file: delete-product-lambda.zip\n  Then:\n   Go to the delete-product Lambda function In the Code section, click Upload from → .zip file   Choose delete-product-lambda.zip, then click Save  Click Deploy after uploading  Set the environment variables:   REGION: your AWS region TABLE_NAME: your DynamoDB table name ORIGINAL_BUCKET: S3 bucket for original images RESIZED_BUCKET: S3 bucket for resized images  Ensure these match your actual resources.\nIf you edit the code in the AWS Console, don’t forget to click Deploy after changes.\n\r Option 2: Build Locally   Download the source: delete-product-source.zip\n  Follow the local build guide at:\nGetPresignedUrl Lambda Function\n  That section includes step-by-step instructions on how to build and zip your Lambda code locally.\n\r Create delete-category Lambda Function on AWS Console  Go to AWS Lambda Console, and click Create function.  On the Create function screen, select Author from scratch, and fill in:   Function name: delete-category Runtime: Node.js 22.x Architecture: x86_64  AWS Lambda currently supports multiple languages like Java, .NET, Python, and Node.js.\nHere, we use Node.js 22.x for better performance and modern syntax support.\n\rUnder Change default execution role:   Choose: Use an existing role Select the role, e.g., lambda-dynamodb-role Click Create function  Lambda currently does not support inline editing with ESM (import/export) in Node.js 22.x.\nYou need to prepare the code locally and upload as a ZIP file.\n\r Option 1: Use Prebuilt .zip File   Download ZIP file: delete-category-lambda.zip\n  Go to the delete-category Lambda function\n   Under Code, click Upload from → .zip file   Choose the downloaded file and click Save  Click Deploy  Set the environment variables:   REGION: your AWS region TABLE_NAME: your DynamoDB table name  Ensure these values match your configurations.\nIf you edit the code in the AWS Console, don’t forget to click Deploy after changes.\n\r Option 2: Build Locally   Download the source: delete-category-source.zip\n  Follow the local build guide at:\nGetPresignedUrl Lambda Function\n  That section includes step-by-step instructions on how to build and zip your Lambda code locally.\n\r"
},
{
	"uri": "/5-config-api-gateway/5.3-enable-cros-and-deloy/",
	"title": "Enable CORS and Deploy API",
	"tags": [],
	"description": "",
	"content": "Overview After configuring resources and methods for the API Gateway, the next step is to enable CORS (Cross-Origin Resource Sharing) so that your frontend (or other apps) can access the API from a different domain. Then, you’ll deploy the API to make it available.\n Add Binary File Support  Go to the API Gateway Console, select your API (e.g. eshop-fcj).  From the left menu, go to API Settings → Binary media types  Under Binary media types, enter:   Binary media type: multipart/form-data Click Save changes  After saving, multipart/form-data should appear in the list:   Enable CORS for Each Method To allow browsers to call your API from different domains (such as a frontend app), you need to enable CORS for each HTTP method (GET, POST, DELETE, etc.) per resource.\nEnable CORS for /products resource  Go to API Gateway Console → open the eshop-fcj API  From the left sidebar, select a Resource like /products. Then click Enable CORS.  In the CORS Settings popup:   Access-Control-Allow-Methods: Select GET, POST, and OPTIONS Access-Control-Allow-Headers: Content-Type,X-Amz-Date,Authorization,X-Api-Key,X-Amz-Security-Token Access-Control-Allow-Origin: * (allow all domains)  Click Save to apply.\nEnable CORS for /products/{id} child resource On the Resource details page for /products/{id}, click Enable CORS  In the CORS Settings popup:   Access-Control-Allow-Methods: Select GET, PUT, DELETE, and OPTIONS Access-Control-Allow-Headers: Content-Type,X-Amz-Date,Authorization,X-Api-Key,X-Amz-Security-Token Access-Control-Allow-Origin: *  Click Save to apply.\n Repeat the same for other resources and methods    Resource Path Access-Control-Allow-Origin Access-Control-Allow-Methods     /products * GET, POST, OPTIONS   /products/{id} * GET, PUT, DELETE, OPTIONS   /categories * GET, POST, OPTIONS   /categories/{id} * GET, DELETE, OPTIONS   /upload-image * POST, OPTIONS    You must repeat these steps for each resource if you want the frontend to be able to call that API endpoint.\n\r Final result after enabling CORS: After enabling CORS for methods like GET, POST, etc., AWS will automatically generate the OPTIONS method, allowing frontend clients to make cross-origin requests without getting CORS errors.\n\r Deploy API Gateway After enabling CORS, you must deploy the API to apply the changes:\n Go to API Gateway Console, select your API (e.g. eshop-fcj)  From the left sidebar, click Deploy API  In the Deploy API dialog: If you haven’t created a stage yet, click [New Stage]  Enter the following:   Stage name: eshop Deployment description: Dev environment  Then click Deploy\n After successful deployment, you will see the following result:\nEvery time you update a method or resource, you must redeploy the API for changes to take effect — and make sure to select the correct stage.\n\r Get Your API URL Once deployed, you will get an Invoke URL, which looks like this:\nhttps://{restapi_id}.execute-api.{region}.amazonaws.com/{stage_name}/{resource_path} "
},
{
	"uri": "/3-writing-data-to-amazon-dynamodb/",
	"title": "Writing Data to DynamoDB",
	"tags": [],
	"description": "",
	"content": "Overview After successfully uploading and processing the images, the next step is to manage application data – such as products and categories – by storing them in a database system.\nIn this section, you will use Amazon DynamoDB – a fully managed NoSQL database service by AWS – to store and query data efficiently. It\u0026rsquo;s especially well-suited for serverless architectures.\nThe product and category data will include:\n Product: name, description, price, resized image URL, category, etc. Category: category name, thumbnail image, etc.   Objectives Create DynamoDB tables for Product and Category to store your application data.\n Create the Product Table in DynamoDB  Go to the DynamoDB Console and click Create Table in the navigation panel.   In the Table details section, enter:\n Table name: Product Partition key: Id (type: string) Leave the Sort key blank unless you need advanced sorting.     Under Table settings:\n Click Customize settings if you want to adjust advanced options like Table class or Capacity mode. Table class: Default is Standard – good for most use cases. If the table is rarely accessed, consider Standard-IA to reduce cost. Capacity mode: Default is On-demand – pay per request with no need to provision capacity. Perfect for MVPs, prototypes, or unpredictable traffic.    If you just want to create the table quickly, you can leave the default settings as they are. These defaults are beginner-friendly and suitable for most use cases.\n\rFinally, scroll down and click Create table to finish.   Create the Category Table in DynamoDB The process for creating the Category table is identical to Product. You just need to:\n  Go back to the DynamoDB Console and click Create Table.\n  In the Table details section, enter:\n Table name: Category Partition key: Id (type: string) Leave the Sort key blank     In the Table settings, you can choose Default settings if no changes are needed.\n  Click Create table to complete.\n   On-demand mode is great for applications with unpredictable or uneven traffic patterns, especially ideal for beginners or experimental systems.\nThe Partition key is mandatory when creating a table and cannot be changed afterward.\nYou can add secondary indexes (Global Secondary Indexes) after the table is created.\n\r Result After creating both Product and Category tables, you will see them listed in the DynamoDB Console.\n"
},
{
	"uri": "/4-deploy-lambda-function/",
	"title": "Deploying Lambda Functions",
	"tags": [],
	"description": "",
	"content": "Overview After setting up a data storage system using DynamoDB, the next step is to build AWS Lambda functions to handle the core business logic of your application. Each function will correspond to a specific data operation such as creating, updating, deleting, or retrieving data from the database.\nLambda is a serverless compute service provided by AWS that allows you to run code without managing servers. You only focus on the business logic, while AWS Lambda automatically handles scaling, event-driven execution, and pay-per-use billing.\n Roles of Lambda Functions In this system, we will implement three basic types of Lambda functions:\n Create/Update functions: Add or update product/category information in DynamoDB. Delete functions: Permanently or softly delete records from the database. Get functions: Retrieve detail by ID or return a list for frontend display.  These functions can be integrated into API Gateway to form a RESTful API or connected to other AWS events (e.g., successful S3 upload, user actions, etc.).\n Preparation: Create an IAM Role for Lambda Before creating Lambda functions, you must create an IAM Role that grants permission to access DynamoDB. This step is mandatory to allow Lambda functions to interact with the database.\nSteps:\n Go to the IAM Console → choose Roles → click Create role Under Trusted entity type, select: AWS service For Use case, choose: Lambda Click Next and attach the following permission:  Search and select: AmazonDynamoDBFullAccess (or use a custom policy to limit access)   Name the role, e.g.: lambda-dynamodb-role Click Create role   Main Steps  Create IAM Role for Lambda Function Lambda Function to Create or Update Data Lambda Function to Delete Data Lambda Function to Get Data  "
},
{
	"uri": "/4-deploy-lambda-function/4.4-get-lambda-function/",
	"title": "Lambda Functions to Get Data",
	"tags": [],
	"description": "",
	"content": "Overview In this step, we will implement the following Lambda functions:\n A Lambda function named get-product – used to retrieve product data from DynamoDB. A Lambda function named get-category – used to retrieve category data from DynamoDB.  These functions are written in Node.js 22.x and use a pre-created IAM Role with permissions to access DynamoDB.\nIn this workshop, each \u0026ldquo;get\u0026rdquo; Lambda handles both listing all items and retrieving a single item by ID.\nThat means you only need one Lambda function for both types of queries.\n\r Create get-product Lambda Function in AWS Console  Go to AWS Lambda Console, and click Create function.  On the Create function screen, select Author from scratch, and in the Basic information section, enter:   Function name: get-product Runtime: Node.js 22.x Architecture: x86_64  AWS Lambda supports various languages like Java, .NET, Python, and Node.js.\nIn this workshop, we use Node.js 22.x – the latest version with better performance and modern syntax support.\n\rIn Change default execution role:   Choose: Use an existing role Select the IAM Role you created, e.g., lambda-dynamodb-role Click Create function  Currently, Lambda does not support inline ESM editing (i.e., import/export) for Node.js 22.x.\nYou must prepare the source code and libraries locally, then upload as a .zip file.\n\r Option 1: Use Prebuilt .zip (Recommended)  Use this if you want a quick deployment without building anything locally.\n   Download the prebuilt ZIP:\nget-product-lambda.zip\n  In AWS Console:\n   Go to the get-product function Under Code, click Upload from → .zip file   Choose get-product-lambda.zip and click Save  Click Deploy  Update the Environment Variables:   REGION: your AWS region TABLE_NAME: DynamoDB table name ORIGINAL_BUCKET: S3 bucket for original images RESIZED_BUCKET: S3 bucket for resized images  Make sure these values match your actual configuration.\nWhen editing code in the AWS Console, remember to click Deploy after changes.\n\r Option 2: Build and Zip Locally   Download the source code:\nget-product-source.zip\n  Follow the build instructions here:\nGetPresignedUrl Lambda Function\n  This section explains how to install libraries and zip your Lambda code for deployment.\n\r Create get-category Lambda Function in AWS Console  Go to AWS Lambda Console, and click Create function.  On the Create function screen, select Author from scratch, and in the Basic information section, enter:   Function name: get-category Runtime: Node.js 22.x Architecture: x86_64  AWS Lambda supports various languages like Java, .NET, Python, and Node.js.\nWe are using Node.js 22.x for modern syntax and optimal performance.\n\rIn Change default execution role:   Choose: Use an existing role Select your IAM Role (e.g., lambda-dynamodb-role) Click Create function  Lambda currently does not support inline ESM editing for Node.js 22.x.\nYou must prepare the code locally and upload a zipped version.\n\r Option 1: Use Prebuilt .zip (Recommended)   Download the ZIP:\nget-category-lambda.zip\n  In AWS Console:\n   Go to the get-category function Under Code, click Upload from → .zip file   Choose the ZIP file and click Save  Click Deploy  Update the Environment Variables:   REGION: your AWS region TABLE_NAME: your DynamoDB table name ORIGINAL_BUCKET: S3 bucket for original images RESIZED_BUCKET: S3 bucket for resized images  Ensure these values match your environment.\nWhen editing code in the AWS Console, remember to click Deploy after changes.\n\r Option 2: Build and Zip Locally   Download the source code:\nget-category-source.zip\n  Follow the build instructions here:\nGetPresignedUrl Lambda Function\n  That section explains how to build and zip the Lambda function for manual deployment.\n\r"
},
{
	"uri": "/5-config-api-gateway/5.4-test-apis-with-postman/",
	"title": "Test APIs with Postman",
	"tags": [],
	"description": "",
	"content": "Overview Once your API Gateway has been deployed and you have the Invoke URL, you can use Postman to test your APIs — such as creating a product, listing items, deleting entries, uploading files, etc.\n Use Postman to Test the API You can access Postman in one of the following ways:\n Web version: Postman in Browser Desktop app: Download Postman   Test Category API Test POST API to Create Category  Get the Invoke URL from Stages in your API Gateway. It typically looks like this:  https://{restapi_id}.execute-api.{region}.amazonaws.com/{stage_name}/{resource_path} In the Postman interface, enter the following details:   Click Create new request using the + icon at the top Select method POST and enter the Invoke URL from the API Gateway you created earlier Then click Send and wait for the response in the Body tab, which will return JSON data like this:  Next, go to the Body tab, select raw, and paste the following JSON snippet:  { \u0026#34;name\u0026#34;: \u0026#34;Điện thoại\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Các dòng điện thoại thông minh từ nhiều thương hiệu.\u0026#34; } Open the Category table in the DynamoDB Console to verify that the data has been saved correctly:  Additionally, you can test the update data function:  Select the PUT method and enter the Invoke URL from API Gateway created earlier. The URL will be in the following format:\nhttps://{restapi_id}.execute-api.{region}.amazonaws.com/{stage_name}/{resource_path}/{id} Test API to retrieve category data   Get the Invoke URL from the Stages section of the created API Gateway.\n  In the Postman interface, enter the following information:\n   Click Create new request (the + icon at the top) Select GET as the method, then enter the Invoke URL obtained earlier Click Send and wait for the response in the body, which should be in JSON format containing the category data  Additionally, you can retrieve category data by ID:   Test API to delete a category   Get the Invoke URL from the Stages section of the created API Gateway.\n  In the Postman interface, enter the following information:\n   Click Create new request (the + icon at the top) Select the DELETE method, then enter the Invoke URL Click Send and wait for the response in the body, which should be in JSON format  Open the Category table in the DynamoDB Console to verify that the data has been deleted:   Test the file upload API Test API to get the pre-signed URL for uploading a file  Get the Invoke URL from the Stages section of the created API Gateway. The URL typically has the following format:  https://{restapi_id}.execute-api.{region}.amazonaws.com/{stage_name}/{resource_path} In the Postman interface, enter the following information:   Click Create new request (the + icon at the top) Select the POST method and paste the Invoke URL obtained from the API Gateway setup Click Send and wait for the response in the body, which should return a JSON object containing the signed URL and related information  Then switch to the Body tab, select raw, and paste the following JSON content:  { \u0026#34;fileName\u0026#34;: \u0026#34;example.jpg\u0026#34;, \u0026#34;fileType\u0026#34;: \u0026#34;image/jpeg\u0026#34; } \rSince we\u0026rsquo;re testing with Postman, make sure to enter the correct file name and file type of the image you want to upload.\n\r In the Postman interface, enter the following details:   Click Create new request (the + icon at the top) Select the PUT method and paste the Invoke URL returned in the previous step (this is the presigned URL)  Then switch to the Body tab, choose binary, and upload the exact image file you specified earlier (e.g., example.jpg with MIME type image/jpeg).   Note: Make sure you upload the exact image file you specified earlier in the fileName and fileType, for example: json\n Make sure to select the correct image file that matches the fileName and fileType you specified earlier.\n\rAfter clicking Send, you can check the result in the two S3 buckets:  "
},
{
	"uri": "/5-config-api-gateway/",
	"title": "Configure API Gateway",
	"tags": [],
	"description": "",
	"content": "Overview To allow Lambda functions to be invoked from the frontend (or tools like Postman, curl, etc.), we need to configure an API layer — this is where Amazon API Gateway comes in.\nAPI Gateway acts as a \u0026ldquo;gateway\u0026rdquo; that enables clients (users) to interact with your Lambda backend in a secure, well-structured, and organized manner.\nIn this section, we will:\n Create a new REST API named eshop-fcj Attach each resource (e.g., /products, /products/{id}) to the corresponding Lambda function Define HTTP methods such as GET, POST, PUT, and DELETE Enable CORS so the frontend can make API calls from the browser Test the API using Postman  Once completed, you will have a fully functional API system that your frontend can call and interact with.\n Key Steps  Create API Gateway Create resources and methods Enable CORS and deploy Test APIs using Postman  "
},
{
	"uri": "/6-setup-cognito-userpool/",
	"title": "Configure Cognito UserPool",
	"tags": [],
	"description": "",
	"content": "Overview Amazon Cognito makes it easy to add sign-up, sign-in, and user management features to your application. In this section, you will:\n Create a User Pool to manage users. Configure required attributes such as email, username, and phone number. Test functionality using Postman with sign-up and sign-in APIs.  Main Content  Create a user pool Test APIs with Postman  "
},
{
	"uri": "/7-authentication-and-authorization/",
	"title": "Authentication and Authorization",
	"tags": [],
	"description": "",
	"content": "Overview In a Serverless system on AWS, security is a critical aspect. Authentication ensures that only valid users can access the system, while authorization determines the level of access for each user group.\nSolution used:\n  Amazon Cognito to manage users and handle login authentication\n  Cognito User Pool Groups to manage user roles\n  API Gateway as the protection layer between clients and backend\n  Lambda Authorizer or Cognito Authorizer to validate access tokens\n  Main Content  User Authentication with Cognito and API Gateway User Authorization using Cognito Groups  "
},
{
	"uri": "/8-deploy-frontend/",
	"title": "Deploy Frontend",
	"tags": [],
	"description": "",
	"content": " Overview Next, we deploy the frontend (user interface) of the modern web application to AWS S3 and CloudFront, ensuring end users can access it via the Internet with high speed, security, and stability.\nThe frontend application is typically a Single Page Application (SPA) built with React, Angular, or Vue. After building, the static assets are uploaded to S3 and CloudFront is used as the CDN to distribute content globally.\nMain Content Create S3 Bucket for Web Files  Go to the AWS S3 Console and click Create bucket.  In General configuration, enter the following:   AWS Region: Choose a single AWS region for all resources (Lambda, S3, DynamoDB, etc.) to reduce latency and simplify IAM (e.g., Asia Pacific (Singapore) ap-southeast-1) Bucket type: General purpose (default) Bucket name: fe-easyshop-fcj  Note: The bucket name must be globally unique and cannot contain spaces or special characters.\n\rIn Block Public Access settings:   Uncheck Block all public access Check the box I acknowledge\u0026hellip; to confirm public access  Scroll down and click Create bucket to finish.  Upload Files to S3  Go to your created bucket (e.g., fe-easyshop-fcj) in the AWS S3 Console.  In the bucket detail page, click Upload.  Upload the following items from the dist folder:   index.html and root files (e.g., vite.svg, favicon.ico) The entire assets/ directory or subdirectories with static files (CSS, JS, images)  Do not upload the entire dist folder, only its contents. Ensure index.html is at the bucket root.\n\rClick Upload to complete. You will see a result like this:  Configure Bucket Policy  In the S3 bucket, go to the Permissions tab.  Scroll to Bucket policy and click Edit.  Paste the following JSON policy:  { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;PublicReadGetObject\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::\u0026lt;your-bucket-name\u0026gt;/*\u0026#34; } ] } Configure Static Website Hosting  Go to the bucket Properties tab. Scroll to Static website hosting, click Edit. Enter the following:   Index document: index.html Error document: index.html (for SPA) Click Save changes  SPA apps use a single HTML file. So, all paths (/products, /cart, etc.) must return index.html to let JavaScript handle routing. Otherwise, S3 returns a 404 error.\n\rSet Up CloudFront CDN for S3 Website  Go to AWS CloudFront Console and click Create Distribution.  In Distribution option:   Name: easyshop-cdn Choose Single website or app Click Next  In Specify origin:   Origin type: Amazon S3 S3 origin: Select your S3 bucket (e.g., fe-easyshop-fcj.s3.ap-southeast-1.amazonaws.com) Click Next  In Enable security:   Choose Do not enable security protections (to avoid extra cost) Click Next  Click Create distribution to finish.  Initially, the selected origin is a REST API endpoint, suitable for backend/API access. For static websites, update to use the website endpoint.\n\rUpdate Origin to Website Endpoint  Go to the distribution details, then to the Origins tab.  Select the origin (e.g., fe-easyshop-fcj.s3.ap-southeast-1.amazonaws.com), click Edit.  In the warning message:   This S3 bucket has static web hosting enabled\u0026hellip;\n  Click Use website endpoint  Scroll down and click Save changes  After creating or editing the Distribution, its status will be \u0026ldquo;Deploying\u0026rdquo;. Wait 3–5 minutes for the updates to take effect.\n\rResult After completing the steps, you’ll get a CloudFront URL like this:\n"
},
{
	"uri": "/9-final-result-verification/",
	"title": "Final Frontend Verification",
	"tags": [],
	"description": "",
	"content": " Overview After successfully deploying the frontend to S3 and configuring CloudFront, verify the entire system by visiting the live website.\nAccessing the Frontend Website Login / Register  Visit /login and /register to test user authentication flows. Ensure Cognito integration works properly.  Registration Page Login Page Admin Page  Log in using an admin account. Visit pages such as /admin/products, /admin/categories Verify you can add, edit, and delete products.  Admin Product Management Page Admin Category Management Page User Page  Visit the homepage or / and confirm that the product list is displayed properly.  Access Denied Page  Log in with a regular user account. Visit the /admin page to verify that the system displays a \u0026ldquo;No access permission\u0026rdquo; message.  "
},
{
	"uri": "/10-clean-up-resources/",
	"title": "Clean Up Resources",
	"tags": [],
	"description": "",
	"content": " Overview After completing the deployment and testing of the serverless system, it’s recommended to clean up all AWS resources to avoid incurring unnecessary costs.\nIn this workshop, we’ve created several resources, including:\n IAM Roles (for Lambda, API Gateway, etc.) Lambda Functions DynamoDB Tables S3 Buckets (original and resized images) Amazon API Gateway Amazon Cognito (User Pool, App Client, etc.) Amazon CloudFront (if used for frontend hosting)   Main Tasks Note: Resource names (IAM roles, buckets, API\u0026hellip;) may vary between users. Carefully verify names before deleting to avoid affecting unrelated services.\n\r1. Delete DynamoDB Tables  Go to the DynamoDB Console → Select:   Table Product Table Category  Then click Delete Table  2. Delete Lambda Functions  Go to the Lambda Console → Delete functions:   create-product create-category get-presigned-url resize-image delete-product \u0026hellip;  Select each function, click Actions \u0026gt; Delete  3. Delete S3 Buckets  Go to the S3 Console   Original bucket: upload-originals-fcj Resized bucket: resized-image-fcj Frontend hosting bucket (if any)   Before deleting a bucket, delete all objects inside it first.\n Then click Delete bucket  4. Delete Amazon API Gateway Visit the API Gateway Console\n  Select the API such as easyshop-api or your custom name\n  Click Delete\n  5. Delete Amazon Cognito Visit the Cognito Console\n Delete User Pool Delete App Client Delete Identity Pool (if any)  6. Delete Amazon CloudFront (if used) Visit the CloudFront Console\n  Select the distribution used for frontend delivery\n  First click Disable, then click Delete\n  7. Delete IAM Roles and Policies  Go to the IAM Console, find and delete roles such as:   lambda-dynamodb-role lambda-resize-image-role lambda-upload-original-role  Select each role, then click Delete role  Conclusion Cleaning up resources is the final step that helps you:\n Avoid unexpected AWS charges Keep your AWS account clean and organized Ensure compliance with security best practices (removing unused permissions and roles)  "
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/mypost/",
	"title": "Content Placeholder",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]